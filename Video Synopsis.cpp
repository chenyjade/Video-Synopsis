#include "Video Synopsis.hpp"

void ForegroundFrameExtract(string src, string aim)
{
    VideoCapture cap;
    cap.open(src);
    
    Mat frame, mask;//current frame

    Mat fgMaskMOG2; //fg mask fg mask generated by MOG2 method

    Ptr<BackgroundSubtractor> pMOG2;
    pMOG2 = createBackgroundSubtractorMOG2();
    
    if(!cap.isOpened())
    {
        cerr << "fail to open!" << endl;
        exit(EXIT_FAILURE);
    }
    
   
    int ex = static_cast<int>(cap.get(CV_CAP_PROP_FOURCC));
    
    cv::Size S = cvSize(static_cast<int>(cap.get(CV_CAP_PROP_FRAME_WIDTH)),static_cast<int>(cap.get(CV_CAP_PROP_FRAME_HEIGHT)));
    cv::VideoWriter writer(aim, ex, cap.get(CV_CAP_PROP_FPS), S, 1);

    double diff, mean, mean2, sigma = 0.01, num;
    num = diff = mean = mean2 = 0.0;

    while(true)
    {
        if(!cap.read(frame))
        {
            cerr << "Unable to read next frame." << endl;
            cerr << "Exiting..." << endl;
            //exit(EXIT_FAILURE);
            break;
        }
       
        medianBlur(frame, mask, 3);
        
        pMOG2 -> apply(mask, fgMaskMOG2);

        diff = diff_count(fgMaskMOG2);
        
        if (num == 0)
        {
            mean = diff;
            mean2 = diff*diff;
            num++;
        }

        else if(diff < abs(mean - 3*sigma))
        {
            mean = diff;
            mean2 = diff*diff;
            num = 1;
        }

        else if(diff > mean + 3*sigma)
        {
            writer << frame;
            extractor++;
        }

        else
        {
            mean2 = (mean*mean*num + diff*diff)/(num + 1);
            mean = (mean*num + diff)/(num + 1);
            sigma = sqrt(abs(mean2 - mean*mean));
            if (sigma <= 0.01)
                sigma = 0.01;
            num++;
        }        
        
    }    
}

void oni_to_AVI(string oni, string aim)
{
    //定义oni文件中视频的总帧数以及得到的图片的保存目录
    int total = 0;
    
    //初始化OpenNI环境
    openni::OpenNI::initialize();
    
    //声明设备并打开oni文件
    openni::Device fromonifile;
    
    fromonifile.open(oni.c_str());
    
    //声明控制对象，这对视频流的控制起到了关键作用
    openni::PlaybackControl* pController = fromonifile.getPlaybackControl();
    
    //声明视频流对象以及帧对象
    openni::VideoStream streamColor;
    openni::VideoFrameRef frameColor;
    
    //验证是否有彩色传感器（是否有彩色视频）和建立与设备想关联的视频流
    if(fromonifile.hasSensor(openni::SENSOR_COLOR))
    {
        if(streamColor.create( fromonifile, openni::SENSOR_COLOR ) == openni::STATUS_OK )
        {
            cout<<"建立视频流成功"<<endl;
        }
        else
        {
            cerr<<"ERROR: 建立视频流没有成功"<<endl;
            system("pause");
            return ;
        }
    }
    else
    {
        cerr << "ERROR: 该设备没有彩色传感器" << endl;
        system("pause");
        return ;
    }
    
    
    //获取总的视频帧数并将该设备的速度设为-1以便能留出足够的时间对每一帧进行处理、显示和保存
    total = pController -> getNumberOfFrames(streamColor);
    pController -> setSpeed(-1);
    
    //开启视频流

    streamColor.start();
    streamColor.readFrame(&frameColor);
    //默认使用motion-jpeg codec, FPS为32
    cv::VideoWriter writer(aim , CV_FOURCC('M', 'J', 'P', 'G'), 32.0, cvSize(frameColor.getWidth(),frameColor.getHeight()),1);

    for (int i = 1;i <= total; ++ i)
    {
        //读取视频流的当前帧
        streamColor.readFrame(&frameColor);
        
        //cout<<"当前正在读的帧数是："<< frameColor.getFrameIndex()<<endl;
        //cout<<"当前的循环次数是：  "<< i << endl;
        
        //将帧保存到Mat中并且将其转换到BGR模式，因为在OpenCV中图片的模式是BGR
        cv::Mat rgbImg(frameColor.getHeight(), frameColor.getWidth(), CV_8UC3, (void*)frameColor.getData());
        
        cv::Mat bgrImg;

        cvtColor(rgbImg, bgrImg, CV_RGB2BGR);

        writer << bgrImg;
        
        if (cv::waitKey(30) == 27)
        {
            break;
        }
    }
    
    //释放video
    
    //关闭视频流
    streamColor.destroy();
    
    //关闭设备
    fromonifile.close();
    
    //关闭OpenNI
    openni::OpenNI::shutdown();
    
    return ;
}

double diff_count(Mat &frontimg)
{
    int count = 0;
    for (int i = 0; i < frontimg.rows; i++)
        for (int j = 0; j < frontimg.cols; j++)
            if (frontimg.at<double>(i, j) != 0)
                count++;

    return double(count) / (frontimg.rows * frontimg.cols);
}
